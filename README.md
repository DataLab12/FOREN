## [ViSIR: Vision Transformer Single Image Reconstruction Method for Earth System Models](https://arxiv.org/abs/2502.06741)

**ViSIR** combines Vision Transformers (ViT) with Sinusoidal Representation Networks (SIRENs) to enhance image super-resolution tasks. The model introduces SIREN-based feedforward layers within the transformer architecture, enabling superior recovery of high-frequency details in the output image.

---

## ğŸ” Overview

ViSIR consists of the following components:

- **Patch Embedding**: Converts input images into non-overlapping patches for transformer processing.
- **Transformer Encoder**: Applies multi-head self-attention to model relationships between patches.
- **SIREN-Driven Feedforward**: Replaces the traditional MLP block with sinusoidal activation layers for better frequency learning.
- **SIREN Decoder**: Maps the processed representation to a high-resolution output image.

---

## ğŸ“ Directory Structure
FinalScoresVitSIRENF*.xlsx                    # Training results (loss, PSNR, SSIM, etc.)

ViTSIREN2comp_image.png                     # Visualization comparisons of output vs ground truth

visir_main.py                                 # Main training script (contains model and pipeline)

â”œâ”€â”€ LR/  Folder with low-resolution input images

â”œâ”€â”€ HR/  Folder with high-resolution ground truth images




## ğŸ§  Model Highlights

- Integrates a ViT encoder with a SIREN-based decoder.
- Uses positional embeddings for patch ordering.
- Enhances reconstruction quality using sine activation functions (SIREN).
- Outputs a high-resolution image that is 3Ã— larger than the input.

---

## Getting Started

### ğŸ”§ Requirements

Install dependencies with pip:

```bash
pip install -r requirements.txt
```

ğŸ–¼ Dataset Preparation
Place your image pairs in the following folders:

LR/: Low-resolution images (e.g., 0.png)

HR/: High-resolution (3Ã—) images with the same filenames (e.g., 0.png)

---

## Run Training
Update the visir_main.py script as needed, then run:

```
python3 VISIR.py
```
---
Inside the script, you can modify:

num_of_images: Total number of image pairs to train on

EPOCHS: Number of training epochs (default: 1000)

Freq: Omegaâ‚€ value for SIREN's sine activation

Layer: Number of hidden layers in the SIREN block

---
## Output Metrics
After training, the model will generate:

âœ… PSNR and SSIM scores

ğŸ“‰ Loss curves and epoch tracking

ğŸ“¸ Visual side-by-side comparisons (ViTSIREN2comp_image#*.png)

ğŸ“‘ An Excel summary of results (FinalScoresVitSIRENF{Freq}H{Layer}.xlsx)

### Metrics
MSE: Pixel-wise error

PSNR: Measures peak signal quality

SSIM: Evaluates structural similarity of images

---

ğŸ“Œ Citation
If this code or architecture helps your research, please consider citing or referencing this repository.

ğŸ™ Acknowledgments
ViSIR builds on ideas from:

[SIREN: Implicit Neural Representations with Periodic Activation Functions](https://arxiv.org/abs/2006.09661)

[An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (ViT)](https://arxiv.org/abs/2010.11929)

---
ğŸ“¬ Contact
For inquiries or collaboration opportunities, feel free to reach out to Ehsan Zeraatkar via [email](mailto:ezeraatkar@gmail.com).




