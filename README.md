# ViSIR: Vision Transformer Single Image Reconstruction Method for Earth System Models

##  [[Paper]](https://arxiv.org/abs/2502.06741)

**ViSIR** combines Vision Transformers (ViT) with Sinusoidal Representation Networks (SIRENs) to enhance image super-resolution tasks. The model introduces SIREN-based feedforward layers within the transformer architecture, enabling superior recovery of high-frequency details in the output image.

---

## ğŸ” Overview

ViSIR consists of the following components:

- **Patch Embedding**: Converts input images into non-overlapping patches for transformer processing.
- **Transformer Encoder**: Applies multi-head self-attention to model relationships between patches.
- **SIREN-Driven Feedforward**: Replaces the traditional MLP block with sinusoidal activation layers for better frequency learning.
- **SIREN Decoder**: Maps the processed representation to a high-resolution output image.

---

## ğŸ“ Directory Structure

â”œâ”€â”€ LR/  Folder with low-resolution input images
â”œâ”€â”€ HR/  Folder with high-resolution ground truth images
â”œâ”€â”€ FinalScoresVitSIRENF*.xlsx # Training results (loss, PSNR, SSIM, etc.)
â”œâ”€â”€ ViTSIREN2comp_image#*.png # Visualization comparisons of output vs ground truth
â”œâ”€â”€ visir_main.py # Main training script (contains model and pipeline)


## ğŸ§  Model Highlights

- Integrates a ViT encoder with a SIREN-based decoder.
- Uses positional embeddings for patch ordering.
- Enhances reconstruction quality using sine activation functions (SIREN).
- Outputs a high-resolution image that is 3Ã— larger than the input.

---

## ğŸ§ª Getting Started

### ğŸ”§ Requirements

Install dependencies with pip:

```bash
pip install torch torchvision matplotlib numpy pillow openpyxl scikit-image
```

ğŸ–¼ Dataset Preparation
Place your image pairs in the following folders:

LR/: Low-resolution images (e.g., 0.png)

HR/: High-resolution (3Ã—) images with the same filenames (e.g., 0.png)

â–¶ï¸ Run Training
Update the visir_main.py script as needed, then run:

```
python visir_main.py
```
nside the script, you can modify:

num_of_images: Total number of image pairs to train on

EPOCHS: Number of training epochs (default: 1000)

Freq: Omegaâ‚€ value for SIREN's sine activation

Layer: Number of hidden layers in the SIREN block

ğŸ“Š Output Metrics
After training, the model will generate:

âœ… PSNR and SSIM scores

ğŸ“‰ Loss curves and epoch tracking

ğŸ“¸ Visual side-by-side comparisons (ViTSIREN2comp_image#*.png)

ğŸ“‘ An Excel summary of results (FinalScoresVitSIRENF{Freq}H{Layer}.xlsx)

Metrics
MSE: Pixel-wise error

PSNR: Measures peak signal quality

SSIM: Evaluates structural similarity of images

ğŸ“Œ Citation
If this code or architecture helps your research, please consider citing or referencing this repository.

ğŸ™ Acknowledgments
ViSIR builds on ideas from:

SIREN: Implicit Neural Representations with Periodic Activation Functions

An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (ViT)

ğŸ“¬ Contact
For inquiries or collaboration opportunities, please reach out to the repository maintainer.


